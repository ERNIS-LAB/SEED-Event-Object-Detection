{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('/home/shenqi/Master_thesis/SEED')\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from metavision_ml.detection.anchors import Anchors\n",
    "from metavision_ml.detection_tracking.display_frame import draw_box_events\n",
    "\n",
    "from Model.feature_extractor import SEED_EventGRU,EMinGRU_ReLUFuseDownsampleConv_ConditionalConv\n",
    "from Model.ssd_head import BoxHead\n",
    "from Model.detection import inference_step,evaluate\n",
    "from utils.dataloader import seq_dataloader\n",
    "import utils.data_augmentation as data_aug\n",
    "from skvideo.io import FFmpegWriter\n",
    "\n",
    "dataset_path = '/media/shenqi/data/Gen4_multi_timesurface_FromDat_super_small'\n",
    "dataset_type = 'gen4'\n",
    "dataloader = seq_dataloader(dataset_path = dataset_path, dataset_type = dataset_type, num_tbins = 1, batch_size = 1, channels = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cout = 256\n",
    "net = EMinGRU_ReLUFuseDownsampleConv_ConditionalConv(dataloader.channels, base=int(cout/16), cout=cout, dataset = dataset_type, pruning = False)\n",
    "box_coder = Anchors(num_levels=net.levels, anchor_list='PSEE_ANCHORS', variances=[0.1, 0.2])\n",
    "ssd_head = BoxHead(net.cout, box_coder.num_anchors, len(dataloader.wanted_keys)+1, n_layers=0)\n",
    "\n",
    "net.load_state_dict(torch.load('/home/shenqi/Master_thesis/SEED/Saved_Model/new_gen4/EMinGRU_ReLUFuseDownsampleConv_ConditionalConv_256_norelu_n15b8/48_model.pth',map_location=torch.device('cuda')))\n",
    "ssd_head.load_state_dict(torch.load('/home/shenqi/Master_thesis/SEED/Saved_Model/new_gen4/EMinGRU_ReLUFuseDownsampleConv_ConditionalConv_256_norelu_n15b8/48_pd.pth',map_location=torch.device('cuda')))\n",
    "\n",
    "net.eval().to('cuda')\n",
    "ssd_head.eval().to('cuda')\n",
    "\n",
    "augment = data_aug.data_augmentation(dataset_type= dataset_type)\n",
    "\n",
    "viz_labels = partial(draw_box_events, label_map=['background']+dataloader.wanted_keys, thickness = 2)\n",
    "video_writer = FFmpegWriter('EMGU_condition.mp4', outputdict={'-vcodec': 'libx264', '-crf': '20', '-preset': 'veryslow','-r': '20'})\n",
    "size_x = 2\n",
    "size_y = 1\n",
    "height_scaled = 360\n",
    "width_scaled = 640\n",
    "frame = np.zeros((size_y * height_scaled, width_scaled * size_x, 3), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=len(dataloader.seq_dataloader_test)) as pbar:\n",
    "    with torch.no_grad():     \n",
    "        for ind, data in enumerate(dataloader.seq_dataloader_test):\n",
    "            pbar.update(1)\n",
    "            \n",
    "            mask = data[\"mask_keep_memory\"]\n",
    "            metadata = dataloader.seq_dataloader_test.dataset.get_batch_metadata(ind)\n",
    "            \n",
    "            data['inputs'] = data['inputs'].to(device='cuda')\n",
    "            if data['frame_is_labeled'].sum().item() != 0:\n",
    "                data = augment(data, only_vertical_move=True)  \n",
    "            \n",
    "            batch = data[\"inputs\"]\n",
    "            \n",
    "            output_val_emgu,*_ = inference_step(data,net,ssd_head,box_coder)\n",
    "            \n",
    "            value_output_val_dt_emguf = list(output_val_emgu['dt'].values())\n",
    "            \n",
    "            \n",
    "            index = 0\n",
    "            t = 0   \n",
    "            im = batch[t][index]\n",
    "            \n",
    "            im = im.cpu().numpy()\n",
    "            \n",
    "            \n",
    "            y, x = divmod(index, size_x)\n",
    "            img = dataloader.seq_dataloader_test.get_vis_func()(im)\n",
    "            \n",
    "            img_emgu = img.copy()\n",
    "        \n",
    "            if viz_labels is not None:\n",
    "                labels = data[\"labels\"][t][index]\n",
    "                img = viz_labels(img, labels)\n",
    "                \n",
    "                if(len(value_output_val_dt_emguf)<1):\n",
    "                    img_emgu = viz_labels(img_emgu, [])\n",
    "                else:\n",
    "                    img_emgu = viz_labels(img_emgu, value_output_val_dt_emguf[0][1])\n",
    "                \n",
    "                \n",
    "            if t <= 1 and not mask[index]:\n",
    "                # mark the beginning of a sequence with a red square\n",
    "                img[:10, :10, 0] = 222\n",
    "            name = metadata[index][0].path.split('/')[-1]\n",
    "            cv2.putText(img, name, (int(0.05 * (width_scaled)), int(0.94 * (height_scaled))),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1.2, (50, 240, 12))\n",
    "            \n",
    "\n",
    "            frame[y * (height_scaled):(y + 1) * (height_scaled),\n",
    "                    x * (width_scaled): (x + 1) * (width_scaled)] = img\n",
    "            frame[y * (height_scaled):(y + 1) * (height_scaled),\n",
    "                (x+1) * (width_scaled): (x + 2) * (width_scaled)] = img_emgu\n",
    "            \n",
    "            \n",
    "            video_writer.writeFrame(frame)\n",
    "            \n",
    "                \n",
    "            \n",
    "    video_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
